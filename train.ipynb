{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Set random seed for reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "# # Source directory\n",
    "# data_dir = '/Users/apunnakula/AJ/mlzoomcap-capstone2/stanford-dogs-dataset-copy'\n",
    "\n",
    "# # Directories for train and validation splits\n",
    "# train_dir = os.path.join(data_dir, 'train')\n",
    "# validation_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "# # Create train and validation directories if they do not exist\n",
    "# os.makedirs(train_dir, exist_ok=True)\n",
    "# os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "# # Fraction of data to be used for validation\n",
    "# validation_fraction = 0.2\n",
    "\n",
    "# # Loop through each breed directory, excluding 'train' and 'validation'\n",
    "# for breed_dir in tqdm(os.listdir(data_dir)):\n",
    "#     breed_path = os.path.join(data_dir, breed_dir)\n",
    "\n",
    "#     # Skip 'train' and 'validation' directories themselves\n",
    "#     if not os.path.isdir(breed_path) or breed_dir in ['train', 'validation']:\n",
    "#         continue\n",
    "\n",
    "#     # List all image files\n",
    "#     images = os.listdir(breed_path)\n",
    "#     random.shuffle(images)\n",
    "\n",
    "#     # Determine split index\n",
    "#     split_index = int(len(images) * (1 - validation_fraction))\n",
    "\n",
    "#     # Split images\n",
    "#     train_images = images[:split_index]\n",
    "#     validation_images = images[split_index:]\n",
    "\n",
    "#     # Create directories for the current breed\n",
    "#     train_breed_dir = os.path.join(train_dir, breed_dir)\n",
    "#     validation_breed_dir = os.path.join(validation_dir, breed_dir)\n",
    "#     os.makedirs(train_breed_dir, exist_ok=True)\n",
    "#     os.makedirs(validation_breed_dir, exist_ok=True)\n",
    "\n",
    "#     # Move files\n",
    "#     for img in train_images:\n",
    "#         shutil.move(os.path.join(breed_path, img), train_breed_dir)\n",
    "\n",
    "#     for img in validation_images:\n",
    "#         shutil.move(os.path.join(breed_path, img), validation_breed_dir)\n",
    "\n",
    "#     # Remove the now-empty breed directory\n",
    "#     os.rmdir(breed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16418 images belonging to 120 classes.\n",
      "Found 4162 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "# data preparation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  \n",
    "\n",
    "# Set the path to the dataset\n",
    "train_dir = '/Users/apunnakula/AJ/mlzoomcap-capstone2/stanford-dogs-dataset-copy/train'\n",
    "validation_dir = '/Users/apunnakula/AJ/mlzoomcap-capstone2/stanford-dogs-dataset-copy/validation'\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Normalization for validation\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 14:30:10.722726: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0245 - loss: 4.7493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apunnakula/AJ/mlzoomcap-capstone2/capstone2/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 79ms/step - accuracy: 0.0245 - loss: 4.7489 - val_accuracy: 0.0961 - val_loss: 4.1006\n",
      "Epoch 2/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1007 - loss: 4.0442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.1007 - loss: 4.0440 - val_accuracy: 0.1511 - val_loss: 3.5875\n",
      "Epoch 3/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.1472 - loss: 3.6970"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 79ms/step - accuracy: 0.1472 - loss: 3.6970 - val_accuracy: 0.1725 - val_loss: 3.4419\n",
      "Epoch 4/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.1724 - loss: 3.5116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - accuracy: 0.1724 - loss: 3.5116 - val_accuracy: 0.1999 - val_loss: 3.3078\n",
      "Epoch 5/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.1943 - loss: 3.4137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.1943 - loss: 3.4137 - val_accuracy: 0.2102 - val_loss: 3.2518\n",
      "Epoch 6/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.2037 - loss: 3.3223 - val_accuracy: 0.2174 - val_loss: 3.2547\n",
      "Epoch 7/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.2143 - loss: 3.2870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.2143 - loss: 3.2870 - val_accuracy: 0.2239 - val_loss: 3.2101\n",
      "Epoch 8/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.2196 - loss: 3.2433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 82ms/step - accuracy: 0.2196 - loss: 3.2433 - val_accuracy: 0.2295 - val_loss: 3.1521\n",
      "Epoch 9/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.2321 - loss: 3.1825 - val_accuracy: 0.2321 - val_loss: 3.1800\n",
      "Epoch 10/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.2290 - loss: 3.1831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - accuracy: 0.2290 - loss: 3.1830 - val_accuracy: 0.2405 - val_loss: 3.1448\n",
      "Epoch 11/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2431 - loss: 3.1187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.2431 - loss: 3.1187 - val_accuracy: 0.2453 - val_loss: 3.1262\n",
      "Epoch 12/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - accuracy: 0.2528 - loss: 3.0920 - val_accuracy: 0.2393 - val_loss: 3.1536\n",
      "Epoch 13/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.2490 - loss: 3.0877 - val_accuracy: 0.2489 - val_loss: 3.1481\n",
      "Epoch 14/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - accuracy: 0.2551 - loss: 3.0490 - val_accuracy: 0.2422 - val_loss: 3.1730\n",
      "Epoch 15/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - accuracy: 0.2656 - loss: 3.0459 - val_accuracy: 0.2468 - val_loss: 3.1682\n",
      "Epoch 16/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2654 - loss: 3.0407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.2654 - loss: 3.0407 - val_accuracy: 0.2556 - val_loss: 3.1033\n",
      "Epoch 17/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.2677 - loss: 3.0009 - val_accuracy: 0.2465 - val_loss: 3.1915\n",
      "Epoch 18/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.2708 - loss: 3.0187 - val_accuracy: 0.2532 - val_loss: 3.1483\n",
      "Epoch 19/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.2745 - loss: 2.9795 - val_accuracy: 0.2571 - val_loss: 3.1823\n",
      "Epoch 20/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.2693 - loss: 2.9961 - val_accuracy: 0.2576 - val_loss: 3.1349\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.2672 - loss: 3.0510\n",
      "VGG16 - Validation Loss: 3.1032955646514893, Validation Accuracy: 0.25564631819725037\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.0088 - loss: 4.9007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 87ms/step - accuracy: 0.0088 - loss: 4.9007 - val_accuracy: 0.0132 - val_loss: 4.8269\n",
      "Epoch 2/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0099 - loss: 4.8365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 82ms/step - accuracy: 0.0099 - loss: 4.8365 - val_accuracy: 0.0132 - val_loss: 4.8115\n",
      "Epoch 3/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 83ms/step - accuracy: 0.0146 - loss: 4.8210 - val_accuracy: 0.0118 - val_loss: 4.8235\n",
      "Epoch 4/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0137 - loss: 4.8116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 83ms/step - accuracy: 0.0137 - loss: 4.8116 - val_accuracy: 0.0125 - val_loss: 4.8112\n",
      "Epoch 5/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0132 - loss: 4.7966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 84ms/step - accuracy: 0.0132 - loss: 4.7966 - val_accuracy: 0.0137 - val_loss: 4.7582\n",
      "Epoch 6/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - accuracy: 0.0157 - loss: 4.7871 - val_accuracy: 0.0163 - val_loss: 4.7836\n",
      "Epoch 7/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 86ms/step - accuracy: 0.0158 - loss: 4.7861 - val_accuracy: 0.0180 - val_loss: 4.7813\n",
      "Epoch 8/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - accuracy: 0.0170 - loss: 4.7853 - val_accuracy: 0.0156 - val_loss: 4.7708\n",
      "Epoch 9/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 86ms/step - accuracy: 0.0168 - loss: 4.7735 - val_accuracy: 0.0175 - val_loss: 4.7754\n",
      "Epoch 10/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0152 - loss: 4.7784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - accuracy: 0.0152 - loss: 4.7784 - val_accuracy: 0.0139 - val_loss: 4.7552\n",
      "Epoch 11/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0170 - loss: 4.7676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 86ms/step - accuracy: 0.0170 - loss: 4.7676 - val_accuracy: 0.0204 - val_loss: 4.7462\n",
      "Epoch 12/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 88ms/step - accuracy: 0.0164 - loss: 4.7562 - val_accuracy: 0.0195 - val_loss: 4.7462\n",
      "Epoch 13/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0163 - loss: 4.7594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 82ms/step - accuracy: 0.0163 - loss: 4.7594 - val_accuracy: 0.0195 - val_loss: 4.7270\n",
      "Epoch 14/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 83ms/step - accuracy: 0.0183 - loss: 4.7558 - val_accuracy: 0.0108 - val_loss: 4.7967\n",
      "Epoch 15/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0169 - loss: 4.7597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 84ms/step - accuracy: 0.0169 - loss: 4.7597 - val_accuracy: 0.0221 - val_loss: 4.7104\n",
      "Epoch 16/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 83ms/step - accuracy: 0.0226 - loss: 4.7382 - val_accuracy: 0.0139 - val_loss: 4.7509\n",
      "Epoch 17/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 84ms/step - accuracy: 0.0175 - loss: 4.7575 - val_accuracy: 0.0180 - val_loss: 4.7412\n",
      "Epoch 18/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.0168 - loss: 4.7610 - val_accuracy: 0.0173 - val_loss: 4.7124\n",
      "Epoch 19/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0179 - loss: 4.7448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 84ms/step - accuracy: 0.0179 - loss: 4.7448 - val_accuracy: 0.0209 - val_loss: 4.7058\n",
      "Epoch 20/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 82ms/step - accuracy: 0.0184 - loss: 4.7474 - val_accuracy: 0.0221 - val_loss: 4.7344\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.0220 - loss: 4.6993\n",
      "ResNet50 - Validation Loss: 4.705803871154785, Validation Accuracy: 0.020903412252664566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/1lksy1zn3hj4fx2pm__f6c2c0000gn/T/ipykernel_30220/3957475068.py:15: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2111 - loss: 4.0108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 83ms/step - accuracy: 0.2112 - loss: 4.0096 - val_accuracy: 0.4476 - val_loss: 2.2696\n",
      "Epoch 2/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 77ms/step - accuracy: 0.3886 - loss: 2.8059 - val_accuracy: 0.4745 - val_loss: 2.4106\n",
      "Epoch 3/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - accuracy: 0.4146 - loss: 2.8557 - val_accuracy: 0.4784 - val_loss: 2.6519\n",
      "Epoch 4/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 76ms/step - accuracy: 0.4357 - loss: 2.8838 - val_accuracy: 0.4680 - val_loss: 2.7414\n",
      "Epoch 5/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 77ms/step - accuracy: 0.4359 - loss: 2.9703 - val_accuracy: 0.4702 - val_loss: 2.8437\n",
      "Epoch 6/20\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 79ms/step - accuracy: 0.4195 - loss: 3.3094 - val_accuracy: 0.4702 - val_loss: 3.2388\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4604 - loss: 2.2464\n",
      "MobileNetV2 - Validation Loss: 2.2696259021759033, Validation Accuracy: 0.44762134552001953\n",
      "The best model is MobileNetV2 with an accuracy of 0.44762134552001953\n"
     ]
    }
   ],
   "source": [
    "# model selection and training\n",
    "\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "def create_model(model_name):\n",
    "    if model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    elif model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    elif model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    else:\n",
    "        raise ValueError(\"Model not recognized\")\n",
    "\n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create a new model on top\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(len(train_generator.class_indices), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define a function to compile, train, and evaluate models\n",
    "def train_evaluate_model(model_name):\n",
    "    model = create_model(model_name)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(f'{model_name}_best_model.h5', save_best_only=True),\n",
    "        EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "    print(f'{model_name} - Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "    return val_accuracy\n",
    "\n",
    "# Train and evaluate each model\n",
    "model_names = ['VGG16', 'ResNet50', 'MobileNetV2']\n",
    "val_accuracies = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    accuracy = train_evaluate_model(model_name)\n",
    "    val_accuracies.append(accuracy)\n",
    "\n",
    "# Find the best model\n",
    "best_model_index = np.argmax(val_accuracies)\n",
    "print(f'The best model is {model_names[best_model_index]} with an accuracy of {val_accuracies[best_model_index]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
